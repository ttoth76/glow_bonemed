---
title: "MSDS_6372_Project2"
author: "Tamas Toth"
date: "`r Sys.Date()`"
output:
  #html_document:
    #theme: cerulean
    #highlight: textmate
  github_document:
  toc: FALSE
  toc_depth: 3
  fig_width: 7
  fig_height: 5
  dev: "png"
  df_print: "default"
  includes: NULL
  md_extensions: NULL
  hard_line_breaks: TRUE
  pandoc_args: NULL
  html_preview: TRUE
  keep_html: TRUE
always_allow_html: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Loading the necessary R libraries for the analysis
```{r message = FALSE}
# Load the necessary libraries
library(knitr)
library(rmarkdown)
# From class
library(GGally)
library(epitools)
library(MASS)
library(tidyverse)
library(car)
library(caret)
library(glmnet)
library(ROCR)
library(pROC)
#Dasta set
library(aplore3)
library(ResourceSelection)

# Other useful libraries
library(dplyr)
library(ggplot2)
library(gplots)

#library(ggpubr)
#library(tidyr)
#library(plyr)
#library(ggthemes)
library(e1071)
#library(class)
#library(stringr)
#library(sjPlot)
#library(data.table)
#library(reshape2)
#library(corrplot)
#library(naivebayes)
#library(egg)
#library(rworldmap)
#library(Hmisc)
#library(DataExplorer)
#library(selectiveInference)
#library(dlookr)
```
```{r message = FALSE}
# Turn off scientific notation
options(scipen = 100, digits = 4)
```

## The Global Longitudinal Study of Osteoporosis in Women
### Objective: Assessing risk factors and predicting if a woman with osteoperosis will have a bone fracture within the first year after joining the study.
#### The study has enrolled over 60,000 women aged 55 and older in ten countries. The major goals of the study are to use the data to provide insights into the management of fracture risk, patient experience with prevention and treatment of fractures and distribution of risk factors among older women on an international scale over the follow up period. The outcome variable is any fracture in the ﬁrst year of follow up. www.outcomes-umassmed.org/glow

## Objective 1 methodology:

1. Understand the data
2. EDA
3. Feature Selection (Penalized Logistic Regression, Stepwise/forward/backward, Manual)
4. Split the data to Training and Test set
5. Fit Logistic Regression model
6. Interpret the model, including hypothesis testing and confidence intervals
7. Conclusion

#### Read the data
```{r,fig.align='center',out.extra='angle=90', message = FALSE}
#Read the data
bonemed_df = glow_bonemed
attach(bonemed_df)
bonemed_df_sample = sample_n(bonemed_df, 5)
knitr::kable(bonemed_df_sample, "html")
dim(bonemed_df)
```

### Data Description
* __sub_id__: Identification Code (1 - n)

* __site_id__: Study Site (1 - 6)

* __phy_id__: Physician ID code (128 unique codes)

* __priorfrac__: History of Prior Fracture (1: No, 2: Yes)

* __age__: Age at Enrollment (Years)

* __weight__: Weight at enrollment (Kilograms)

* __height__: Height at enrollment (Centimeters)

* __bmi__: Body Mass Index (Kg/m^2)

* __premeno__: Menopause before age 45 (1: No, 2: Yes)

* __momfrac__: Mother had hip fracture (1: No, 2: Yes)

* __armassist__: Arms are needed to stand from a chair (1: No, 2: Yes)

* __smoke__: Former or current smoker (1: No, 2: Yes)

* __raterisk__: Self-reported risk of fracture (1: Less than others of the same age, 2: Same as others of the same age, 3: Greater than others of the same age)

* __fracscore__: Fracture Risk Score (Composite Risk Score)

* __fracture__: Any fracture in first year (1: No, 2: Yes)

* __bonemed__: Bone medications at enrollment (1: No, 2: Yes)

* __bonemed_fu__: Bone medications at follow-up (1: No, 2: Yes)

* __bonetreat__: Bone medications both at enrollment and follow-up (1: No, 2: Yes)


```{r}
#set random seed
set.seed(329)
```

#### Address the missing values in each column (NA as well as empty strings).
```{r}
# Address the missing values in each column (NA as well as empty strings).
missing_df = as.data.frame(sapply(bonemed_df, function(x) sum(is.na(x))))
colnames(missing_df) = c("missing values")
knitr::kable(missing_df, "html")
empty_string_df = as.data.frame(sapply(bonemed_df, function(x) sum(x == "")))
colnames(empty_string_df) = c("empty string")
knitr::kable(empty_string_df, "html")
```

```{r, warning=FALSE}
# Function to Identify different characteristics of the data frame 
# Getting a concise summary of the dataframe: str()
# Listing the column labels of the dataframe: colnames()
# Size of the dataset: dim()
# # Verify if there is any negative values in the dataset
dfinfo = function(df_name)
  {
  df_structure = str(df_name)
  df_colnames = colnames(df_name)
  df_dimensions = dim(df_name)
  
  num_cols = bonemed_df %>% dplyr::select(where(is.numeric)) %>% colnames()
  df_neg = print(paste("Negative values in the variable:",  
                       sapply(bonemed_df[,num_cols], function(x) sum(x < 0))))
  
  outparam = list(df_structure, df_colnames, df_dimensions, df_neg)
  return (outparam)
}
```
```{r}
dfinfo(bonemed_df)
```

### Observations:
* The data set is comprised of 500 observations and 18 variables
* There are numerical and categorical variables in the data set
* There are no missing values or empty strings in the data set
* No negative values in the data set
* ??????No duplicated records
* 'fracture' is the dependent variable


#####################################################################################
#                                Exploratory Data Analysis                          #
#####################################################################################
```{r pair plots, fig.align='center',out.extra='angle=90', message = FALSE}
num_cols = bonemed_df %>% dplyr::select(where(is.numeric)) %>% colnames()
pair_plot = c(num_cols, 'fracture')
pair_plot = pair_plot[-1]
ggpairs(bonemed_df[,pair_plot],aes(color=fracture, alpha = 0.5))
```

### Observations:
* Height for fracture 'No' and 'Yes' levels seem to be normally distributed.
* Weight and bmi are strongly positively linearly correlated for both factor levels.
* Age and fracscore are strongly positively linearly correlated for both factor levels.
* There are more "No" fracture in the first year observations than "Yes"


```{r}
# Summary statistics
t(aggregate(.~ fracture,data=bonemed_df,summary))
```

### Observations:
* The minimum age for "No" fracture in the first year is 55. The minimum age for "Yes" fracture in the first year is 56.
* The maximum age for "No" fracture in the first year is 99. The maximum age for "Yes" fracture in the first year is 89.
* The median age for "No" fracture in the first year is 66. The median age for "Yes" fracture in the first year is 72.
* The mean age for "No" fracture in the first year is 67.49. The mean age for "Yes" fracture in the first year is 71.79.
* Age is a likely is good predictor of fracture in the first year since there is a observable difference in median and mean age of having a fracture. 

* The minimum weight for "No" fracture in the first year is 39.9. The minimum weight for "Yes" fracture in the first year is 45.8.
* The maximum weight for "No" fracture in the first year is 127. The maximum weight for "Yes" fracture in the first year is 124.7.
* The median weight for "No" fracture in the first year is 68. The median weight for "Yes" fracture in the first year is 68.
* The mean weight for "No" fracture in the first year is 72.17. The mean weight for "Yes" fracture in the first year is 70.79.
* Weight does not seem to be a significant variable for predicting fracture in the first year as the median and mean weight values are very similar to the factor levels.

* The minimum height for "No" fracture in the first year is 142. The minimum height for "Yes" fracture in the first year is 134.
* The maximum height for "No" fracture in the first year is 199. The maximum height for "Yes" fracture in the first year is 178.
* The median height for "No" fracture in the first year is 162. The median height for "Yes" fracture in the first year is 160.
* The mean height for "No" fracture in the first year is 161.9. The mean height for "Yes" fracture in the first year is 159.9.
* Height seems to be a good predictor for fracture in the first year.

* The minimum bmi for "No" fracture in the first year is 14.88. The minimum bmi for "Yes" fracture in the first year is 17.04.
* The maximum bmi for "No" fracture in the first year is 49.08 The maximum bmi for "Yes" fracture in the first year is 44.04.
* The median bmi for "No" fracture in the first year is 26.37. The median bmi for "Yes" fracture in the first year is 26.43.
* The mean bmi for "No" fracture in the first year is 27.50. The mean bmi for "Yes" fracture in the first year is 27.71.
* BMI does not seem to be a significant predictor for fracture in the first year.

* The minimum Fracture Risk Score for "No" fracture in the first year is 0. The minimum Fracture Risk Score for "Yes" fracture in the first year is 0.
* The maximum Fracture Risk Score for "No" fracture in the first year is 11. The maximum Fracture Risk Score for "Yes" fracture in the first year is 9.
* The median Fracture Risk Score for "No" fracture in the first year is 3. The median Fracture Risk Score for "Yes" fracture in the first year is 5.
* The mean Fracture Risk Score for "No" fracture in the first year is 3.317. The mean Fracture Risk Score for "Yes" fracture in the first year is 4.840.
* Fracture Risk Score seems to be a significant predictor for fracture in the first year.

#####################################################################################
#                               Categorical data plots                              #
#####################################################################################
```{r,fig.align='center',out.extra='angle=90', fig.dim = c(8, 6)}

cat_cols = bonemed_df %>% dplyr::select(where(is.factor)) %>% colnames()

# Plot all categorical variables
for (c in cat_cols)
{
  cat_plot = bonemed_df %>% ggplot(aes(x= .data[[c]], group = 1)) + 
    geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
    geom_text(aes( label = scales::percent(..prop..),
                   y= ..prop.. ), stat= "count", vjust = -.5) +
    labs(y = "Percent") +
    scale_y_continuous(labels = scales::percent) + theme(legend.position = "none") +
    ggtitle(paste(c, "Categorical Analysis")) + 
    theme(plot.title = element_text(hjust = 0.5)) + 
    theme(axis.text.x = element_text(vjust = 0.5, hjust=1)) # +
    egg::ggarrange(cat_plot, ncol=2) 
}
```

### Observations:
* 75% of the observations have no prior history of fracture. 25% of the observations have prior history of fracture.
* 81% of the observations have no menopause before age 45. 19% of the observations have menopause before age 45.
* 87% of the subjects' mother had no hip fracture. 13% of the subjects' mother had hip fracture.
* 62% of the subjects do not need arms to stand from a chair. 38% of the subjects need arms to stand from a chair.
* 93% of the subjects don't smoke. 7% of the subjects smoke are former or current smoker.
* 33.4% of the subjects reported less risk of fractures than others of the same age. 37.2% of the subjects reported the same risk of fractures than others of the same age. 29.4% of the subjects reported greater risk of fractures than others of the same age.
* 75% of the patients do not have any fractures in first year. 25% of the patients have any fractures in first year.
* 74% of the subjects have enrolled to Bone medications. 26% of the subjects have not enrolled to Bone medications.
* 72% of the subjects did not require bone medications at follow-up. 28% of the subjects required bone medications at follow-up.
* 76% of the patients did not receive bone medications at either enrollment or follow-up. 24% of the patients received bone medications both at enrollment and follow-up.



#####################################################################################
#                     Bi-variate analysis with Fracture variable                    #
#####################################################################################
```{r,fig.align='center',out.extra='angle=90'}

num_cols = bonemed_df %>% dplyr::select(where(is.numeric)) %>% colnames()
bivar_plot = num_cols[c(-1, -2, -3)]


for (i in bivar_plot)
{
multibox = bonemed_df %>%
  ggplot(aes(x=fracture, y = .data[[i]])) +
  geom_boxplot(fill = "sandybrown", color = "black") + 
  xlab("Fracture") +
  ylab(i) + stat_summary(fun=mean, geom="point", shape=20, size=7, color="red", fill="red") +
  ggtitle(paste(i, "vs Fracture bi-variate analysis")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Oranges")  
egg::ggarrange(multibox, ncol=2)
}
```

### Observations:
* We can see an increasing in median and mean age for those who had any fractures in the first year.
* Median and mean weight for both fracture levels are very similar.
* The median and mean height are lower for those who had fracture in the first year. This is likely because the bone density is reduced and the subjects shrunk.
* Median and mean BMI is very similar for both factor levels.
* The mean and median fracture risk score is higher for those who had any fracture in the first year.


#####################################################################################
#                                     Correlation plot                              #
#####################################################################################
```{r correlation plot}
corr_df = bonemed_df[,c('age', 'weight', 'height', 'bmi', 'fracscore')]
cont_var.cor = cor(corr_df)
heatmap.2(cont_var.cor,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("row"), 
          symm=F,symkey=T,symbreaks=T, scale="none")
```

### Observations:
* weight and bmi are more similar to each other therefore they would form a cluster
* height, weight and bmi are also similar but more distant from each other. Still can form a cluster.
* age and fracscore are also similar to each other and can form a cluster


```{r}
# Label encoding Yes=1; No=0
bonemed_df$fracture.num<-ifelse(bonemed_df$fracture=="Yes",1,0)
```


#####################################################################################
#                                       Loess plots                                 #
#####################################################################################
```{r, Loess plot}
num_cols = bonemed_df %>% dplyr::select(where(is.numeric)) %>% colnames()
loess_plot = num_cols[c(-1, -2, -3, -9)]

for (i in loess_plot)
{
loess = bonemed_df %>% 
ggplot(aes(x=.data[[i]],y=fracture.num))+
geom_point()+
geom_smooth(formula = y ~ x, method="loess")+
theme(plot.title = element_text(hjust = 0.5)) +
ggtitle(paste(i, "vs fracture loess smoothing"))
egg::ggarrange(loess, ncol=2)
}
```

### Observations:
* The Loess plots show the 'height' has an  S curve like logistic model. The curve is trending down.
* The other continuous predictors don't seem to be important predicting fracture in the first year.


#####################################################################################
#                   Loess plots to investigate interactions                         #
#####################################################################################
```{r, Loess plot interaction}
num_cols = bonemed_df %>% dplyr::select(where(is.numeric)) %>% colnames()
loess_plot = num_cols[c(-1, -2, -3, -9)]

for (j in cat_cols)
{
  for (i in loess_plot)
  {
  plot1 = ggplot(bonemed_df,aes(x=.data[[i]],y=fracture.num,colour=.data[[j]]))+geom_point()+
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle(paste(i, "&", j, " interaction with fracture"))+
  geom_smooth(formula = y ~ x, method="loess",size=1,span=1.5)+facet_wrap(~.data[[j]])
  ylim(-.2,1.2)
  show(plot1)
  }
}
```

## Observations:
* There is a interaction with weight and priorfrac
* There is a interaction with bmi and priorfrac
* There is a interaction with fracscore and priorfrac
* There is a interaction with weight and raterisk
* There is a interaction with bmi and raterisk
* There is a interaction with weight and bonemed
* There is a interaction with bmi and bonemed
* There is a interaction with weight and bonemed_fu
* There is a interaction with bmi and bonemed_fu
* There is a interaction with weight and bonetreat
* There is a interaction with bmi and bonetreat


#####################################################################################
#                    Split the Data to Train and Test sets (85%-15%)               #
#####################################################################################
```{r train test set}
bonmed_df_split = bonemed_df[,-c(1, 2, 3)]
index<-sample(1:dim(bonmed_df_split)[1],round(dim(bonmed_df_split)[1]*0.85),replace=F)
train = bonmed_df_split[index,]
test = bonmed_df_split[-index,]
```

#####################################################################################
#                                   Feature Selection                               #
#####################################################################################

## Manual / Intuition selection
```{r, feature selection manual selection}
# Fit each variable separately and check the p-value for significance

# priorfrac
simple.log.priorfrac<-glm(fracture~priorfrac,family=binomial(link='logit'),data=train)
simple.log.priorfrac.sum = summary(simple.log.priorfrac)

# age
simple.log.age<-glm(fracture~age,family=binomial(link='logit'),data=train)
simple.log.age.sum = summary(simple.log.age)

# weight
simple.log.weight<-glm(fracture~weight,family=binomial(link='logit'),data=train)
simple.log.weight.sum = summary(simple.log.weight)

# height
simple.log.height<-glm(fracture~height,family=binomial(link='logit'),data=train)
simple.log.height.sum = summary(simple.log.height)

# bmi
simple.log.bmi<-glm(fracture~bmi,family=binomial(link='logit'),data=train)
simple.log.bmi.sum = summary(simple.log.bmi)

# premeno
simple.log.premeno<-glm(fracture~premeno,family=binomial(link='logit'),data=train)
simple.log.premeno.sum = summary(simple.log.premeno)

# momfrac
simple.log.momfrac<-glm(fracture~momfrac,family=binomial(link='logit'),data=train)
simple.log.momfrac.sum = summary(simple.log.momfrac)

# armassist
simple.log.armassist<-glm(fracture~armassist,family=binomial(link='logit'),data=train)
simple.log.armassist.sum = summary(simple.log.armassist)

# smoke
simple.log.smoke<-glm(fracture~smoke,family=binomial(link='logit'),data=train)
simple.log.smoke.sum = summary(simple.log.smoke)

# raterisk
simple.log.raterisk<-glm(fracture~raterisk,family=binomial(link='logit'),data=train)
simple.log.raterisk.sum = summary(simple.log.raterisk)

# fracscore
simple.log.fracscore<-glm(fracture~fracscore,family=binomial(link='logit'),data=train)
simple.log.fracscore.sum = summary(simple.log.fracscore)

# bonemed
simple.log.bonemed<-glm(fracture~bonemed,family=binomial(link='logit'),data=train)
simple.log.bonemed.sum = summary(simple.log.bonemed)

# bonemed_fu
simple.log.bonemed_fu<-glm(fracture~bonemed_fu,family=binomial(link='logit'),data=train)
simple.log.bonemed_fu.sum = summary(simple.log.bonemed_fu)

# bonetreat
simple.log.bonetreat<-glm(fracture~bonetreat,family=binomial(link='logit'),data=train)
simple.log.bonetreat.sum = summary(simple.log.bonetreat)
```


```{r, print result of manual selection}
# priorfrac
simple.log.priorfrac.sum$coefficients

# age
simple.log.age.sum$coefficients

# weight
simple.log.weight.sum$coefficients

# height
simple.log.height.sum$coefficients

# bmi
simple.log.bmi.sum$coefficients

# premeno
simple.log.premeno.sum$coefficients

# momfrac
simple.log.momfrac.sum$coefficients

# armassist
simple.log.armassist.sum$coefficients

# smoke
simple.log.smoke.sum$coefficients

# raterisk
simple.log.raterisk.sum$coefficients

# fracscore
simple.log.fracscore.sum$coefficients

# bonemed
simple.log.bonemed.sum$coefficients

# bonemed_fu
simple.log.bonemed_fu.sum$coefficients

# bonetreat
simple.log.bonetreat.sum$coefficients
```

### Observations:
* We can see that the following variables are statistically significant since p-value < 0.05:
 1. priorfracYes
 2. age
 3. height
 4. armassistYes
 5. rateriskSame
 6. rateriskGreater
 7. fracscore
 8. bonemedYes
 9. bonemed_fuYes
 10. bonetreatYes
 
 This result is in-line with what we have observed through EDA for the continuous variables. 
 Next, let's fit all the variables and observe the effect and see how it is changing the significance of the predictors.


## Fit all variables at the same time to check effects 
```{r, all variables manual}
multi_var.log<-glm(fracture~priorfrac+age+weight+height+bmi+premeno+momfrac+armassist+smoke+raterisk+fracscore+bonemed+
                     bonemed_fu+bonetreat,family=binomial(link='logit'),data=train)
multi_var.log.sum = summary(multi_var.log)
multi_var.log.sum$coefficients
```


### Observations:
* Fitting all variables to the logistic regression model, it shows that only 'rateriskGreater', 'bonmed', 'bonemed_fu' and 'bonetreat' are statistically significant. 

Let's test other feature selection methods as well.

## Stepwise selection

```{r, stepwise}
bonemed_df.step = train[,c('priorfrac', 'age', 'weight', 'height', 'bmi', 'premeno', 'momfrac', 'armassist', 'smoke', 'raterisk', 'fracscore', 
                                'bonemed', 'bonemed_fu', 'bonetreat', 'fracture')]
step.full.log = glm(fracture~.,family=binomial(link='logit'),data=bonemed_df.step)
step.log = step.full.log %>% stepAIC(trace=FALSE)
```

```{r}
summary(step.log)
exp(cbind("Odds ratio" = coef(step.log), confint.default(step.log, level = 0.95)))
vif(step.log)
```

## Obseravtions:
* Running a stepwise selection to identify the predictors the process is selecting:
* priorfrac
* age
* weight
* bmi
* momfrac
* armassist
* raterisk
* bonemed
* bonemed_fu
* bonetreat

## PCA
```{r, PCA}
# Let's use PCA to see if the continuous variables separate or not

num_cols = train %>% dplyr::select(where(is.numeric)) %>% colnames()
pca_var = num_cols[c(-6)]
pca_df = train[pca_var]

pc.result=prcomp(pca_df,scale.=TRUE)
pc.scores=pc.result$x
pc.scores=data.frame(pc.scores)
pc.scores$fracture=train$fracture

#plot the first few pc's
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC1 and PC2 on Fracture")

# Let's check lower PCs
ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC1 and PC3 on Fracture")

ggplot(data = pc.scores, aes(x = PC1, y = PC4)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC1 and PC4 on Fracture")

ggplot(data = pc.scores, aes(x = PC1, y = PC5)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC1 and PC5 on Fracture")

ggplot(data = pc.scores, aes(x = PC2, y = PC3)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC2 and PC3 on Fracture")

ggplot(data = pc.scores, aes(x = PC2, y = PC4)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC2 and PC4 on Fracture")

ggplot(data = pc.scores, aes(x = PC2, y = PC5)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC2 and PC5 on Fracture")

ggplot(data = pc.scores, aes(x = PC3, y = PC4)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC3 and PC4 on Fracture")

ggplot(data = pc.scores, aes(x = PC3, y = PC5)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC3 and PC5 on Fracture")

ggplot(data = pc.scores, aes(x = PC4, y = PC5)) +
  geom_point(aes(col=fracture), size=1)+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PC4 and PC5 on Fracture")

par(mfrow=c(1,2))
eigenvals = (pc.result$sdev)^2
plot(1:5,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop = cumsum(eigenvals/sum(eigenvals))
plot(1:5,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
```

```{r, loess for PCI}
for (i in colnames(pc.scores))
{
loess_pca = pc.scores %>% 
ggplot(aes(x=.data[[i]],y=train$fracture.num))+
geom_point()+
geom_smooth(formula = y ~ x, method="loess")+
theme(plot.title = element_text(hjust = 0.5)) +
ggtitle(paste(i, " test"))
egg::ggarrange(loess_pca, ncol=2)
}
```


## Observations:
* The levels in the PCA graph are completely intermixed. There is no obvious separation in the PCA.
* The Scree Plot shows that if we include PC1 that will explain ~50% of the variation of the dataset
* The cumulative proportion plot helps us see that PC1, PC2, PC3 combined explains the variation ~98% but if we add PC4 than 100% of the variation is explained.
* This lets us conclude that we need 'age', 'weight', 'height' and 'bmi' to explain 100% of the variation in the data.
* The loess plot of PCA shows that PC3 is the only continous variable which could be important for predicting fracture in the first year.


## Penalized logistic regression (LASSO)
```{r, data prep for penalized logistic regression}
# Dummy code categorical predictor variables
x = model.matrix(fracture~., train)[,-c(1,17)]

# Convert the outcome (class) to a numerical variable
y <- train$fracture.num
```

```{r, lasso feature selection}
# 5-fold cross validation
cv.lasso <- trainControl(
  method = "repeatedcv", 
  number = 5,
  repeats = 10,
  savePredictions = TRUE,
  summaryFunction=mnLogLoss,
  classProbs = TRUE
)

lasso.logreg.mod = train(
  fracture ~  priorfrac+age+weight+height+bmi+premeno+momfrac+armassist+smoke+raterisk+fracscore+bonemed+bonemed_fu+bonetreat,
  data = train,
  method = "glmnet",
  family = "binomial",
  trControl = cv.lasso,
  metric = "logLoss")

plot(lasso.logreg.mod)
coef(lasso.logreg.mod$finalModel,lasso.logreg.mod$finalModel$lambdaOpt)

# Final LASSO model refit with glm
lasso.mod.final=glm(fracture ~  priorfrac+age+height+bmi+premeno+momfrac+armassist+smoke+raterisk+fracscore+bonemed+bonemed_fu+bonetreat, 
                    family = binomial(link='logit'), data = train)

# ODD ratios for interpretation
exp(cbind("Odds ratio" = coef(lasso.mod.final), confint.default(lasso.mod.final, level = 0.95)))
```

## Observations and interpretations of the LASSO coeffficients:

#####################################################################################
#                                       Predictions                                 #
#####################################################################################

```{r, vif function}
# VIF score function
vif_score = function(model_name)
{
  vif_values = vif(model_name)[,3]
  barplot(vif_values, main = 'VIF Values', horiz = TRUE, col="blue", xlim = c(0,12))
  abline(v=10, col="red")
  return (vif_values)
}
```

```{r, y.test}
y.test = model.matrix(fracture~., test)[,-c(1,17)]
```
#####################################################################################
#                                       LASSO                                       #
#####################################################################################
```{r, LASSO Predict}

# Predicting on the final LASSO model TRAINing data
lasso.mod.final.pred.train <- predict(lasso.mod.final, newdata = train, type = "response")

# Predicting on the final LASSO model TEST data
lasso.mod.final.pred.test <- predict(lasso.mod.final, newdata = test, type = "response")

################ LASSO ROC Curve ######################################

lasso.roc.test = prediction(lasso.mod.final.pred.test, test$fracture,label.ordering=c("No","Yes"))
roc.lasso.test = performance(lasso.roc.test, measure = "tpr", x.measure = "fpr")
plot(roc.lasso.test,colorize = TRUE)
abline(a=0, b= 1)

AUC = auc(test$fracture, lasso.mod.final.pred.test)
print(paste("Area Under the Cuve: ", AUC))
print(paste("LASSO AIC Score: ", AIC(lasso.mod.final)))

#alternative approach
lasso.roc<-roc(response=test$fracture,predictor=lasso.mod.final.pred.test,levels=c("No","Yes"))
plot(lasso.roc,print.thres="best") #This graph is nice because the x axis is plotted in terms of specificity rather than FPR
auc(lasso.roc)

cutoff.lasso = 0.212

# Confusion matrix train
class.lasso.final.train = factor(ifelse(lasso.mod.final.pred.train>cutoff.lasso,"Yes","No"),levels=c("No","Yes"))

#Confusion Matrix for LASSO
print("Confusion matrix for LASSO TRAINING")
confusionMatrix(table(class.lasso.final.train,train$fracture), positive = "Yes")


################ Misclassification rate train ######################################
#cross.table.lasso.train = table(table(class.lasso.final.train,train$fracture))
#MCR_lasso.train = (cross.table.lasso.train[2]+cross.table.lasso.train[3])/dim(train)[1]
misClasificError.lasso.train = mean(class.lasso.final.train != train$fracture)
print(paste('Misclassification Rate for lasso on training set: ', misClasificError.lasso.train))
#####################################################################################################

# Confusion matrix test
class.lasso.final.test<-factor(ifelse(lasso.mod.final.pred.test>cutoff.lasso,"Yes","No"),levels=c("No","Yes"))

#Confusion Matrix for LASSO
print("Confusion matrix for LASSO TEST with 0.5 cutoff")
confusionMatrix(table(class.lasso.final.test,test$fracture), positive = "Yes")

################ Misclassification rate test ######################################
#cross.table.lasso.test = table(class.lasso.final.test,test$fracture)
#MCR_lasso.test = (cross.table.lasso.test[2]+cross.table.lasso.test[3])/dim(test)[1]
#print(paste('Misclassification Rate for LASSO selection on test set: ', MCR_lasso.test))
misClasificError.lasso.test = mean(class.lasso.final.test != test$fracture)
print(paste('Misclassification Rate for lasso on test set: ', misClasificError.lasso.test))
```

## Assumprions
```{r, fit after feature selection2}
# Checking logistic regression model assumptions

# The Observations are Independent
# We can assume that the observations are not coming from repeated measures

#There is No Multicollinearity Among Explanatory Variables
### Visualize VIF
#vif_score(lasso.mod)


# There are No Extreme Outliers (cooks D)
#influenceIndexPlot(lasso.mod)

# There is a Linear Relationship Between Explanatory Variables and the Logit of the Response Variable

# Influential point analysis and residual plots
#residualPlots(lasso.mod)
#influenceIndexPlot(lasso.mod)
#influencePlot(lasso.mod)
```


## Observations:
## All assumptions are met:
* __The Response Variable is Binary__: 'Fracture' as a response variable is a factor with binary levels (Yes/No)
* __Independence__: We can assume that the observations are independent
* __Multicolliearity__: The is no multicollinearity among the explanatory variables (VIF values show no multicollinearity)
* __Outliers__: The largest Cooks D value is 0.015 which indicates that there is no extreme outlier
* __The Sample Size is Sufficiently Large__: ?

* Sensitivity: The probability that the model predicts a positive outcome for an observation when indeed the outcome is positive. This is also called the “true positive rate.”
* Specificity: The probability that the model predicts a negative outcome for an observation when indeed the outcome is negative. This is also called the “true negative rate.”


## Model scoring
```{r model scoring lasso}
## Add misclassification rate
```

#####################################################################################
#                                       Stepwise                                    #
#####################################################################################
```{r, Stepwise Predict}

# Predicting on the final Stepwise model TRAINing data
stepwise.mod.final.pred.train <- predict(step.log, newdata = train, type = "response")

# Predicting on the final Stepwise model TEST data
stepwise.mod.final.pred.test <- predict(step.log, newdata = test, type = "response")

################ Stepwise ROC Curve ######################################
library(ROCR)
stepwise.roc.test = prediction(stepwise.mod.final.pred.test, test$fracture,label.ordering=c("No","Yes"))
roc.stepwise.test = performance(stepwise.roc.test, measure = "tpr", x.measure = "fpr")
plot(roc.stepwise.test,colorize = TRUE)
abline(a=0, b= 1)

AUC = auc(test$fracture, stepwise.mod.final.pred.test)
print(paste("Area Under the Cuve: ", AUC))
print(paste("Stepwise AIC Score: ", AIC(step.log)))


#alternative approach
step.roc<-roc(response=test$fracture,predictor=stepwise.mod.final.pred.test,levels=c("No","Yes"))
plot(step.roc,print.thres="best") #This graph is nice because the x axis is plotted in terms of specificity rather than FPR

cutoff.step = 0.159

# Confusion matrix stepwise train
class.stepwise.final.train<-factor(ifelse(stepwise.mod.final.pred.train>cutoff.step,"Yes","No"),levels=c("No","Yes"))

#Confusion Matrix for Stepwise train
print("Confusion matrix for Stepwise TRAINING with 0.5 cutoff")
confusionMatrix(table(class.stepwise.final.train,train$fracture), positive = "Yes")

#####################################################################################################

# Confusion matrix
class.stepwise.final.test<-factor(ifelse(stepwise.mod.final.pred.test>cutoff.step,"Yes","No"),levels=c("No","Yes"))

#Confusion Matrix for Stepwise
print("Confusion matrix for Stepwise TEST with 0.5 cutoff")
confusionMatrix(table(class.stepwise.final.test,test$fracture), positive = "Yes")



#misClasificError.stepwise.test = mean(class.stepwise.final.test != test$fracture)
#print(paste('Misclassification Rate for stepwise on test set: ', misClasificError.stepwise.test))


# ODD ratios for interpretation
summary(step.log)
exp(cbind("Odds ratio" = coef(step.log), confint.default(step.log, level = 0.95)))



```


#####################################################################################
#                                       Manual/Intuition                            #
#####################################################################################

```{r, manual selection prediction}
# 5-fold cross validation
cv <- trainControl(
  method = "repeatedcv", 
  number = 5,
  repeats = 10,
  savePredictions = TRUE,
  summaryFunction=mnLogLoss,
  classProbs = TRUE
)

MLogReg = train(
  fracture ~  age + bonemed + bonemed_fu + bonetreat,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = cv,
  metric = "logLoss")

### Visualize VIF
MLogReg_VIF = vif(MLogReg$finalModel)
barplot(MLogReg_VIF, main = 'VIF Values (Custom Logistic Regression', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")

### Hypothesis testing
summary(MLogReg$finalModel)

anova(MLogReg$finalModel, test="Chisq")

library(ResourceSelection) 
hoslem.test(MLogReg$finalModel$y,fitted(MLogReg))

# Predicting
MLogReg.pred.train = predict(MLogReg, train, type = 'prob')
MLogReg.pred.test = predict(MLogReg, test, type = 'prob')

AUC = auc(test$fracture, MLogReg.pred.test$Yes)
print(paste("Area Under the Cuve: ", AUC))
print(paste("Manual model AIC Score: ", MLogReg$finalModel$aic))


################ Manual ROC Curve ######################################
manual.roc<-roc(response=test$fracture,predictor=MLogReg.pred.test$Yes,levels=c("No","Yes"))
plot(manual.roc,print.thres="best")

cutoff.manual = 0.231

#Confusion Matrix for manual model
class.manual.train<-ifelse(MLogReg.pred.train$Yes > cutoff.manual,"Yes","No")
class.manual.train<-factor(class.manual.train)

class.manual.test<-ifelse(MLogReg.pred.test$Yes > cutoff.manual,"Yes","No")
class.manual.test<-factor(class.manual.test)

confusionMatrix(table(class.manual.train,train$fracture), positive = "Yes")
confusionMatrix(table(class.manual.test,test$fracture), positive = "Yes")

```


#####################################################################################
#                                       Objective II                                #
#####################################################################################

```{r, interaction}
cv.ii <- trainControl(
  method = "repeatedcv", 
  number = 5,
  repeats = 10,
  savePredictions = TRUE,
  summaryFunction=mnLogLoss,
  classProbs = TRUE
)

MLogReg.ii = train(
  fracture ~  age + height + bonemed_fu + bonetreat + bmi*bonemed_fu + bmi*bonemed + I(age^2) + I(height^3),
  data = train,
  method = "glm",
  family = "binomial",
  trControl = cv,
  metric = "logLoss")

### Hypothesis testing
summary(MLogReg.ii$finalModel)

anova(MLogReg.ii$finalModel, test="Chisq")


hoslem.test(MLogReg.ii$finalModel$y,fitted(MLogReg.ii))

# Predicting
MLogReg.ii.pred.train = predict(MLogReg.ii, train, type = 'prob')
MLogReg.ii.pred.test = predict(MLogReg.ii, test, type = 'prob')

AUC = auc(test$fracture, MLogReg.ii.pred.test$Yes)
print(paste("Area Under the Cuve: ", AUC))
print(paste("Manual model with interactions and polynomial terms AIC Score: ", MLogReg.ii$finalModel$aic))


################ Manual ROC Curve ######################################
manual.roc<-roc(response=test$fracture,predictor=MLogReg.ii.pred.test$Yes,levels=c("No","Yes"))
plot(manual.roc,print.thres="best")

cutoff.manual = 0.23

#Confusion Matrix for manual model
class.manual.train.ii<-ifelse(MLogReg.ii.pred.train$Yes > cutoff.manual,"Yes","No")
class.manual.train.ii<-factor(class.manual.train)

class.manual.test.ii<-ifelse(MLogReg.ii.pred.test$Yes > cutoff.manual,"Yes","No")
class.manual.test.ii<-factor(class.manual.test)

confusionMatrix(table(class.manual.train.ii,train$fracture), positive = "Yes")
confusionMatrix(table(class.manual.test.ii,test$fracture), positive = "Yes")

### Visualize VIF
#MLogReg_ii_VIF = vif(MLogReg.ii$finalModel)
#barplot(MLogReg_ii_VIF, main = 'VIF Values (Custom Logistic Regression with interactions', horiz = TRUE, col="blue", xlim = c(0,12))
#abline(v=10, col="red")

```



